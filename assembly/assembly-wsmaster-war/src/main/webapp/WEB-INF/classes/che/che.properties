#
# Copyright (c) 2012-2018 Red Hat, Inc.
# This program and the accompanying materials are made
# available under the terms of the Eclipse Public License 2.0
# which is available at https://www.eclipse.org/legal/epl-2.0/
#
# SPDX-License-Identifier: EPL-2.0
#
# Contributors:
#   Red Hat, Inc. - initial API and implementation
#

### Che server

# Folder where Che will store internal data objects
che.database=${che.home}/storage

# API service. Browsers initiate REST communications to Che server with this URL
che.api=http://${CHE_HOST}:${CHE_PORT}/api

# Che websocket major endpoint. Provides basic communication endpoint
# for major websocket interaction/messaging.
che.websocket.endpoint=ws://${CHE_HOST}:${CHE_PORT}/api/websocket

# Che websocket minor endpoint. Provides basic communication endpoint
# for minor websocket interaction/messaging.
che.websocket.endpoint_minor=ws://${CHE_HOST}:${CHE_PORT}/api/websocket-minor

# Your projects are synchronized from the Che server into the machine running each
# workspace. This is the directory in the ws runtime where your projects are mounted.
che.workspace.storage=${che.home}/workspaces

# Your projects are synchronized from the Che server into the machine running each
# workspace. This is the directory in the machine where your projects are placed.
che.workspace.projects.storage=/projects

# Used when devfile k8s/os type components requests project PVC creation
# (applied in case of unique and perWorkspace PVC strategy. In case of common PVC strategy,
# it will be rewritten with value of che.infra.kubernetes.pvc.quantity property)
che.workspace.projects.storage.default.size=1Gi

# Defines the directory inside the machine where all the workspace logs are placed.
# The value of this folder should be provided into machine e.g. like environment variable
# so agents developers can use this directory for backup agents logs.
che.workspace.logs.root_dir=/workspace_logs

# Configures proxies used by runtimes powering workspaces
che.workspace.http_proxy=
che.workspace.https_proxy=
che.workspace.no_proxy=

# By default, when users access to a workspace with its URL the workspace
# automatically starts if it is stopped. You can set this to false to disable this.
che.workspace.auto_start=true

# Workspace threads pool configuration, this pool is used for workspace related
# operations that require asynchronous execution e.g. starting/stopping.
# Possible values are 'fixed', 'cached'
che.workspace.pool.type=fixed

# This property is ignored when pool type is different from 'fixed'.
# Configures the exact size of the pool, if it's set multiplier property is ignored.
# If this property is not set(0, < 0, NULL) then pool sized to number of cores,
# it can be modified within multiplier
che.workspace.pool.exact_size=30

# This property is ignored when pool type is different from 'fixed' or exact pool size is set.
# If it's set the pool size will be N_CORES * multiplier
che.workspace.pool.cores_multiplier=2

# This property specifies how much threads to use for workspaces servers liveness probes
che.workspace.probe_pool_size=10


# Http proxy setting for workspace JVM
che.workspace.http_proxy_java_options=NULL

# Java command line options to be added to JVM's that running within workspaces.
che.workspace.java_options=-XX:MaxRAM=150m -XX:MaxRAMFraction=2 -XX:+UseParallelGC -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20 -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xms20m -Djava.security.egd=file:/dev/./urandom

# Maven command line options added to JVM's that run agents within workspaces.
che.workspace.maven_options=-XX:MaxRAM=150m -XX:MaxRAMFraction=2 -XX:+UseParallelGC -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20 -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xms20m -Djava.security.egd=file:/dev/./urandom

# Default java command line options to be added to JVM that run maven server.
che.workspace.maven_server_java_options=-XX:MaxRAM=128m -XX:MaxRAMFraction=1 -XX:+UseParallelGC -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20 -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xms20m -Djava.security.egd=file:/dev/./urandom

# RAM limit default for each machine that has no RAM settings in environment.
che.workspace.default_memory_limit_mb=1024

# RAM request default for each container that has no explicit RAM settings in environment.
# this amount will be allocated on workspace container creation
# this property might not be supported by all infrastructure implementations:
# currently it is supported by k8s and openshift
# if default memory request is more than the memory limit, request will be ignored,
# and only limit will be used
che.workspace.default_memory_request_mb=200


# CPU limit default for each container that has no CPU settings in environment.
# Can be specified either in floating point cores number, e.g. 0.125 or in K8S format integer millicores e.g. 125m
che.workspace.default_cpu_limit_cores=2

# CPU request default for each container that has no CPU settings in environment.
# if default CPU request is more than the CPU limit, request will be ignored,
# and only limit will be used
che.workspace.default_cpu_request_cores=0.125

# RAM limit and request default for each sidecar that has no RAM settings in Che plugin configuration.
che.workspace.sidecar.default_memory_limit_mb=128
che.workspace.sidecar.default_memory_request_mb=64

# CPU limit and request default for each sidecar that has no CPU settings in Che plugin configuration.
# Can be specified either in floating point cores number, e.g. 0.125 or in K8S format integer millicores e.g. 125m
che.workspace.sidecar.default_cpu_limit_cores=1
che.workspace.sidecar.default_cpu_request_cores=0.115

# Define image pulling strategy for sidecars.
# Possible values are: Always, Never, IfNotPresent. Any other value
# will be interpreted as unspecified policy (Always if :latest tag is specified,
# or IfNotPresent otherwise.)
che.workspace.sidecar.image_pull_policy=Always


# Period of inactive workspaces suspend job execution.
che.workspace.activity_check_scheduler_period_s=60

# The period of the cleanup of the activity table. The activity table can contain invalid or stale data
# if some unforeseen errors happen, like a server crash at a peculiar point in time. The default is to
# run the cleanup job every hour.
che.workspace.activity_cleanup_scheduler_period_s=3600

# The delay after server startup to start the first activity clean up job.
che.workspace.activity_cleanup_scheduler_initial_delay_s=60


# Delay before first workspace idleness check job started to avoid
# mass suspend if ws master was unavailable for period close to
# inactivity timeout.
che.workspace.activity_check_scheduler_delay_s=180

# Period of stopped temporary workspaces cleanup job execution.
che.workspace.cleanup_temporary_initial_delay_min=5
che.workspace.cleanup_temporary_period_min=180

# Number of sequential successful pings to server after which it is treated as available.
# Note: the property is common for all servers e.g. workspace agent, terminal, exec etc.
che.workspace.server.ping_success_threshold=1

# Interval, in milliseconds, between successive pings to workspace server.
che.workspace.server.ping_interval_milliseconds=3000

# List of servers names which require liveness probes
che.workspace.server.liveness_probes=wsagent/http,exec-agent/http,terminal,theia,jupyter,dirigible,cloud-shell

# Limit size of the logs collected from single container that can be observed by che-server when
# debugging workspace startup.
# default 10MB=10485760
che.workspace.startup_debug_log_limit_bytes=10485760

### Templates

# Folder that contains JSON files with code templates and samples
che.template.storage=${che.home}/templates


### Authentication parameters

# Che has a single identity implementation, so this does not change the user experience.
# If true, enables user creation at API level
che.auth.user_self_creation=false

# Authentication error page address
che.auth.access_denied_error_page=/error-oauth

# Reserved user names
che.auth.reserved_user_names=

# You can setup GitHub OAuth to automate authentication to remote repositories.
# You need to first register this application with GitHub OAuth.
che.oauth.github.clientid=NULL
che.oauth.github.clientsecret=NULL
che.oauth.github.authuri= https://github.com/login/oauth/authorize
che.oauth.github.tokenuri= https://github.com/login/oauth/access_token
che.oauth.github.redirecturis= http://localhost:${CHE_PORT}/api/oauth/callback

# Configuration of OpenShift OAuth client. Used to obtain OpenShift OAuth token.
che.oauth.openshift.clientid=NULL
che.oauth.openshift.clientsecret=NULL
che.oauth.openshift.oauth_endpoint= NULL
che.oauth.openshift.verify_token_url= NULL

### Internal

# Che extensions can be scheduled executions on a time basis.
# This configures the size of the thread pool allocated to extensions that are launched on
# a recurring schedule.
schedule.core_pool_size=10

# Everrest is a Java Web Services toolkit that manages JAX-RS & web socket communications
# Users should rarely need to configure this.
# Disable asynchronous mechanism that is embedded in everrest.
org.everrest.asynchronous=false

# Quantity of asynchronous requests which may be processed at the same time
org.everrest.asynchronous.pool.size=20

# Size of queue. If asynchronous request can't be processed after consuming it will be added in queue.
org.everrest.asynchronous.queue.size=500

# Timeout in minutes for request. If after timeout request is not done or client did not come yet to get result of request it may be discarded.
org.everrest.asynchronous.job.timeout=10

# Size of cache for waiting, running and ended request.
org.everrest.asynchronous.cache.size=1024

# Path to asynchronous service
org.everrest.asynchronous.service.path=/async/

# DB initialization and migration configuration
db.schema.flyway.baseline.enabled=true
db.schema.flyway.baseline.version=5.0.0.8.1
db.schema.flyway.scripts.prefix=
db.schema.flyway.scripts.suffix=.sql
db.schema.flyway.scripts.version_separator=__
db.schema.flyway.scripts.locations=classpath:che-schema

### Kubernetes Infra parameters

# Configuration of Kubernetes client that Infra will use
che.infra.kubernetes.master_url=
che.infra.kubernetes.trust_certs=

# Defines the way how servers are exposed to the world in k8s infra.
# List of  strategies implemented in Che: default-host, multi-host, single-host
che.infra.kubernetes.server_strategy=default-host

# Used to generate domain for a server in a workspace in case property `che.infra.kubernetes.server_strategy` is set to `multi-host`
che.infra.kubernetes.ingress.domain=

# DEPRECATED - please do not change the value of this property otherwise the existing workspaces will loose data. Do not
# set it on new installations.
#
# Defines Kubernetes namespace in which all workspaces will be created.
# If not set, every workspace will be created in a new namespace, where namespace = workspace id
# It's possible to use <username> and <userid> placeholders (e.g.: che-workspace-<username>).
# In that case, new namespace will be created for each user. Service account with permission
# to create new namespace must be used.
#
# Ignored for OpenShift infra. Use `che.infra.openshift.project` instead
#
# If the namespace pointed to by this property exists, it will be used for all workspaces. If it does not exist,
# the namespace specified by the che.infra.kubernetes.namespace.default will be created and used.
che.infra.kubernetes.namespace=

# Defines Kubernetes default namespace in which user's workspaces are created
# if user does not override it.
# It's possible to use <username>, <userid> and <workspaceid> placeholders (e.g.: che-workspace-<username>).
# In that case, new namespace will be created for each user (or workspace).
# Is used by OpenShift infra as well to specify Project
che.infra.kubernetes.namespace.default=<username>-che

# Defines if a user is able to specify Kubernetes namespace (or OpenShift project) different from the default.
# It's NOT RECOMMENDED to configured true without OAuth configured. This property is also used by the OpenShift infra.
che.infra.kubernetes.namespace.allow_user_defined=false

# Defines Kubernetes Service Account name which should be specified to be bound to all workspaces pods.
# Note that Kubernetes Infrastructure won't create the service account and it should exist.
# OpenShift infrastructure will check if project is predefined(if `che.infra.openshift.project` is not empty):
#  - if it is predefined then service account must exist there
#  - if it is 'NULL' or empty string then infrastructure will create new OpenShift project per workspace
#    and prepare workspace service account with needed roles there
che.infra.kubernetes.service_account_name=NULL

# Specifies an optional, additional cluster role to use with the workspace service account, to allow for addition
# Note that the cluster role name must already exist, and the Che service account needs to be able to create a Role Binding
# to associate this cluster role with the workspace service account.
che.infra.kubernetes.cluster_role_name=NULL

# Defines time frame that limits the Kubernetes workspace start time
che.infra.kubernetes.workspace_start_timeout_min=8

# Defines the timeout in minutes that limits the period for which Kubernetes Ingress become ready
che.infra.kubernetes.ingress_start_timeout_min=5

# If during workspace startup an unrecoverable event defined in the property occurs,
# terminate workspace immediately instead of waiting until timeout
che.infra.kubernetes.workspace_unrecoverable_events=FailedMount,FailedScheduling,MountVolume.SetUp failed,Failed to pull image,FailedCreate

# Defines whether use the Persistent Volume Claim for che workspace needs
# e.g backup projects, logs etc or disable it.
che.infra.kubernetes.pvc.enabled=true

# Defined which strategy will be used while choosing PVC for workspaces.
#
# Supported strategies:
# - 'common'
#        All workspaces in the same Kubernetes Namespace will reuse the same PVC.
#        Name of PVC may be configured with 'che.infra.kubernetes.pvc.name'.
#        Existing PVC will be used or new one will be created if it doesn't exist.
#
# - 'unique'
#        Separate PVC for each workspace's volume will be used.
#        Name of PVC is evaluated as '{che.infra.kubernetes.pvc.name} + '-' + {generated_8_chars}'.
#        Existing PVC will be used or a new one will be created if it doesn't exist.
#
# - 'per-workspace'
#        Separate PVC for each workspace will be used.
#        Name of PVC is evaluated as '{che.infra.kubernetes.pvc.name} + '-' + {WORKSPACE_ID}'.
#        Existing PVC will be used or a new one will be created if it doesn't exist.
che.infra.kubernetes.pvc.strategy=common

# Defines whether to run a job that creates workspace's subpath directories in persistent volume for the 'common' strategy before launching a workspace.
# Necessary in some versions of OpenShift/Kubernetes as workspace subpath volume mounts are created with root permissions,
# and thus cannot be modified by workspaces running as a user (presents an error importing projects into a workspace in Che).
# The default is "true", but should be set to false if the version of Openshift/Kubernetes creates subdirectories with user permissions.
# Relevant issue: https://github.com/kubernetes/kubernetes/issues/41638
# Note that this property has effect only if the 'common' PVC strategy used.
che.infra.kubernetes.pvc.precreate_subpaths=true

# Defines the settings of PVC name for che workspaces.
# Each PVC strategy suplies this value differently.
# See doc for che.infra.kubernetes.pvc.strategy property
che.infra.kubernetes.pvc.name=claim-che-workspace

# Defines the storage class of Persistent Volume Claim for the workspaces.
# Empty strings means "use default".
che.infra.kubernetes.pvc.storage_class_name=

# Defines the size of Persistent Volume Claim of che workspace.
# Format described here:
# https://docs.openshift.com/container-platform/latest/dev_guide/compute_resources.html#dev-compute-resources
che.infra.kubernetes.pvc.quantity=10Gi

# Pod that is launched when performing persistent volume claim maintenance jobs on OpenShift
che.infra.kubernetes.pvc.jobs.image=centos:centos7

# Image pull policy of container that used for the maintenance jobs on Kubernetes/OpenShift cluster
che.infra.kubernetes.pvc.jobs.image.pull_policy=IfNotPresent

# Defines pod memory limit for persistent volume claim maintenance jobs
che.infra.kubernetes.pvc.jobs.memorylimit=250Mi

# Defines Persistent Volume Claim access mode.
# Note that for common PVC strategy changing of access mode affects the number of simultaneously running workspaces.
# If OpenShift flavor where che running is using PVs with RWX access mode then a limit of running workspaces at the same time
# bounded only by che limits configuration like(RAM, CPU etc).
# Detailed information about access mode is described here:
# https://docs.openshift.com/container-platform/latest/architecture/additional_concepts/storage.html#pv-access-modes
che.infra.kubernetes.pvc.access_mode=ReadWriteOnce

# Defines whether Che Server should wait workspaces PVCs to become bound after creating.
# It's used by all PVC strategies.
#
# It should be set to `false` in case if `volumeBindingMode` is configured to `WaitForFirstConsumer`
# otherwise workspace starts will hangs up on phase of waiting PVCs.
#
# Default value is true (means that PVCs should be waited to be bound)
che.infra.kubernetes.pvc.wait_bound=true

# Defined range of ports for installers servers
#
# By default, installer will use own port, but if it conflicts with another installer servers
# then OpenShift infrastructure will reconfigure installer to use first available from this range
che.infra.kubernetes.installer_server_min_port=10000
che.infra.kubernetes.installer_server_max_port=20000

# Defines annotations for ingresses which are used for servers exposing. Value depends on the kind of ingress
# controller.
#
# OpenShift infrastructure ignores this property because it uses Routes instead of ingresses.
#
# Note that for a single-host deployment strategy to work, a controller supporting URL rewriting has to be
# used (so that URLs can point to different servers while the servers don't need to support changing the app root).
# The che.infra.kubernetes.ingress.path.rewrite_transform property defines how the path of the ingress should be
# transformed to support the URL rewriting and this property defines the set of annotations on the ingress itself
# that instruct the chosen ingress controller to actually do the URL rewriting, potentially building on the path
# transformation (if required by the chosen ingress controller).
#
# For example for nginx ingress controller 0.22.0 and later the following value is recommended:
# {"ingress.kubernetes.io/rewrite-target": "/$1","ingress.kubernetes.io/ssl-redirect": "false",\
#     "ingress.kubernetes.io/proxy-connect-timeout": "3600","ingress.kubernetes.io/proxy-read-timeout": "3600"}
# and the che.infra.kubernetes.ingress.path.rewrite_transform should be set to "%s(.*)"
#
# For nginx ingress controller older than 0.22.0, the rewrite-target should be set to merely "/" and the path transform
# to "%s" (see the the che.infra.kubernetes.ingress.path.rewrite_transform property).
#
# Please consult the nginx ingress controller documentation for the explanation of how the ingress controller uses
# the regular expression present in the ingress path and how it achieves the URL rewriting.
che.infra.kubernetes.ingress.annotations_json=NULL

# Defines a "recipe" on how to declare the path of the ingress that should expose a server.
# The "%s" represents the base public URL of the server and is guaranteed to end with a forward slash. This property
# must be a valid input to the String.format() method and contain exactly one reference to "%s".
#
# Please see the description of the che.infra.kubernetes.ingress.annotations_json property to see how these two
# properties interplay when specifying the ingress annotations and path.
#
# If not defined, this property defaults to "%s" (without the quotes) which means that the path is not transformed in
# any way for use with the ingress controller.
che.infra.kubernetes.ingress.path_transform=NULL

# Defines security context for pods that will be created by Kubernetes Infra
#
# This is ignored by OpenShift infra
che.infra.kubernetes.pod.security_context.run_as_user=NULL
che.infra.kubernetes.pod.security_context.fs_group=NULL

# Defines grace termination period for pods that will be created by Kubernetes / OpenShift infrastructures
#
# Grace termination period of Kubernetes / OpenShift workspace's pods defaults '0', which allows to terminate
# pods almost instantly and significantly decrease the time required for stopping a workspace.
# Note: if `terminationGracePeriodSeconds` have been explicitly set in Kubernetes / OpenShift recipe it will not be overridden.
che.infra.kubernetes.pod.termination_grace_period_sec=0

# Number of maximum concurrent async web requests
# (http requests or ongoing  web socket calls)
# supported in the underlying shared http client
# of the `KubernetesClient` instances.
# Default values are 64, and 5 per-host, which
# doesn't seem correct for multi-user scenarios
# knowing that Che keeps a number of connections
# opened (e.g. for command or ws-agent logs)
che.infra.kubernetes.client.http.async_requests.max=1000
che.infra.kubernetes.client.http.async_requests.max_per_host=1000

# Max number of idle connections in the connection pool
# of the Kubernetes-client shared http client
che.infra.kubernetes.client.http.connection_pool.max_idle=5

# Keep-alive timeout of the connection pool
# of the Kubernetes-client shared http client
# in minutes
che.infra.kubernetes.client.http.connection_pool.keep_alive_min=5

# Creates Ingresses with Transport Layer Security (TLS) enabled
# In OpenShift infrastructure, Routes will be TLS-enabled
che.infra.kubernetes.tls_enabled=false

# Name of a secret that should be used when creating workspace ingresses with TLS
# Ignored by OpenShift infrastructure
che.infra.kubernetes.tls_secret=

# Data for TLS Secret that should be used for workspaces Ingresses
# cert and key should be encoded with Base64 algorithm
# These properties are ignored by OpenShift infrastructure
che.infra.kubernetes.tls_key=NULL
che.infra.kubernetes.tls_cert=NULL

# Defines the period with which runtimes consistency checks will be performed.
# If runtime has inconsistent state then runtime will be stopped automatically.
# Value must be more than 0 or `-1`, where `-1` means that checks won't be performed at all.
#
# It is disabled by default because there is possible Che Server configuration when Che Server
# doesn't have an ability to interact with Kubernetes API when operation is not invoked by user.
#
# It DOES work on the following configurations:
# - workspaces objects are created in the same namespace where Che Server is located;
# - cluster-admin service account token is mount to Che Server pod;
#
# It DOES NOT work on the following configurations:
# - Che Server communicates with Kubernetes API using token from OAuth provider;
che.infra.kubernetes.runtimes_consistency_check_period_min=-1

### OpenShift Infra parameters

# Since OpenShift infrastructure reuse Kubernetes infrastructure components
# OpenShift infrastructure reuse most of the Kubernetes configuration attributes.

# DEPRECATED - please do not change the value of this property otherwise the existing workspaces will loose data. Do not
# set it on new installations.
#
# Defines OpenShift namespace in which all workspaces will be created.
# If not set, every workspace will be created in a new project, where project name = workspace id
# It's possible to use <username> and <userid> placeholders (e.g.: che-workspace-<username>).
# In that case, new project will be created for each user. OpenShift oauth or service account with
# permission to create new projects must be used.
#
# If the project pointed to by this property exists, it will be used for all workspaces. If it does not exist,
# the namespace specified by the che.infra.kubernetes.namespace.default will be created and used.
che.infra.openshift.project=

# Single port mode wildcard domain host & port. nip.io is used by default
che.singleport.wildcard_domain.host=NULL
che.singleport.wildcard_domain.port=NULL

# Enable single port custom DNS without inserting the IP
che.singleport.wildcard_domain.ipless=false

### Experimental properties

# Next properties are subject to changes and removal, so do not rely on them in a stable Che assembly

# Docker image of Che plugin broker app that resolves workspace tooling configuration and copies
# plugins dependencies to a workspace
che.workspace.plugin_broker.metadata.image=quay.io/eclipse/che-plugin-metadata-broker:v3.1.2
che.workspace.plugin_broker.artifacts.image=quay.io/eclipse/che-plugin-artifacts-broker:v3.1.2

# Docker image of Che plugin broker app that resolves workspace tooling configuration and copies
# plugins dependencies to a workspace
che.workspace.plugin_broker.pull_policy=Always

# Defines the timeout in minutes that limits the max period of result waiting for plugin broker.
che.workspace.plugin_broker.wait_timeout_min=3

# Workspace tooling plugins registry endpoint. Should be a valid HTTP URL.
# Example: http://che-plugin-registry-eclipse-che.192.168.65.2.nip.io
# In case Che plugins tooling is not needed value 'NULL' should be used
che.workspace.plugin_registry_url=https://che-plugin-registry.prod-preview.openshift.io/v3

# Devfile Registry endpoint. Should be a valid HTTP URL.
# Example: http://che-devfile-registry-eclipse-che.192.168.65.2.nip.io
# In case Che plugins tooling is not needed value 'NULL' should be used
che.workspace.devfile_registry_url=https://che-devfile-registry.prod-preview.openshift.io/

# Defines a default value for persist volumes that clients like Dashboard
# should propose for users during workspace creation.
# Possible values: true or false
# In case of true - PersistentVolumeClaims are used by declared volumes by user and plugins. `true`
# value is supposed not to be set explicitly in Devfile attributes since it's default fixed behaviour.
# In case of false - emptyDir is used instead of PVCs. Note that data will be lost after workspace restart.
che.workspace.persist_volumes.default=true

# Configures in which way secure servers will be protected with authentication.
# Suitable values:
#   - 'default': jwtproxy is configured in a pass-through mode.
#       So, servers should authenticate requests themselves.
#   - 'jwtproxy': jwtproxy will authenticate requests.
#       So, servers will receive only authenticated ones.
che.server.secure_exposer=default

# Jwtproxy issuer string, token lifetime and optional auth page path to route unsigned requests to.
che.server.secure_exposer.jwtproxy.token.issuer=wsmaster
che.server.secure_exposer.jwtproxy.token.ttl=8800h
che.server.secure_exposer.jwtproxy.auth.loader.path=/_app/loader.html
che.server.secure_exposer.jwtproxy.image=quay.io/eclipse/che-jwtproxy:fd94e60
che.server.secure_exposer.jwtproxy.memory_limit=128mb


### Configuration of major "/websocket" endpoint

# Maximum size of the JSON RPC processing pool
# in case if pool size would be exceeded message execution will be rejected
che.core.jsonrpc.processor_max_pool_size=50

# Initial json processing pool. Minimum number of threads that used to process major JSON RPC messages.
che.core.jsonrpc.processor_core_pool_size=5

# Configuration of queue used to process Json RPC messages.
che.core.jsonrpc.processor_queue_capacity=100000

### Configuration of major "/websocket-minor" endpoint

# Maximum size of the JSON RPC processing pool
# in case if pool size would be exceeded message execution will be rejected
che.core.jsonrpc.minor_processor_max_pool_size=100

# Initial json processing pool. Minimum number of threads that used to process minor JSON RPC messages.
che.core.jsonrpc.minor_processor_core_pool_size=15

# Configuration of queue used to process Json RPC messages.
che.core.jsonrpc.minor_processor_queue_capacity=10000

# Port the the http server endpoint that would be exposed with Prometheus metrics
che.metrics.port=8087

### CORS settings

# CORS filter on WS Master is turned off by default.
# Use environment variable "CHE_CORS_ENABLED=true" to turn it on
# "cors.allowed.origins" indicates which request origins are allowed
che.cors.allowed_origins=*

# "cors.support.credentials" indicates if it allows processing of requests with credentials
# (in cookies, headers, TLS client certificates)
che.cors.allow_credentials=false

### Factory defaults

# Editor and plugin which will be used for factories which are created from remote git repository
# which doesn't contain any Che-specific workspace descriptors (like .devfile of .factory.json)
# Multiple plugins must be comma-separated, for example:
# pluginFooPublisher/pluginFooName/pluginFooVersion,pluginBarPublisher/pluginBarName/pluginBarVersion
che.factory.default_editor=eclipse/che-theia/next
che.factory.default_plugins=eclipse/che-machine-exec-plugin/nightly

### Devfile defaults

# Default Editor that should be provisioned into Devfile if there is no specified Editor
# Format is `editorPublisher/editorName/editorVersion` value.
# `NULL` or absence of value means that default editor should not be provisioned.
che.workspace.devfile.default_editor=eclipse/che-theia/next

# Default Plugins which should be provisioned for Default Editor.
# All the plugins from this list that are not explicitly mentioned in the user-defined devfile
# will be provisioned but only when the default editor is used or if the user-defined editor is
# the same as the default one (even if in different version).
# Format is comma-separated `pluginPublisher/pluginName/pluginVersion` values, and URLs. For example:
# eclipse/che-theia-exec-plugin/0.0.1,eclipse/che-theia-terminal-plugin/0.0.1,https://cdn.pluginregistry.com/vi-mode/meta.yaml
# If the plugin is a URL, the plugin's meta.yaml is retrieved from that URL.
che.workspace.devfile.default_editor.plugins=eclipse/che-machine-exec-plugin/nightly
